{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FinalTermLab.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muhammad0Awais/AMLLabs/blob/main/FinalTermLab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "average-extension"
      },
      "source": [
        "## <center>Final Exam Lab\n",
        "```\n",
        "- Advanced Machine Learning, Innopolis University \n",
        "- Professor: Muhammad Fahim \n",
        "- Teaching Assistant: Gcinizwe Dlamini\n",
        "```\n",
        "<hr>\n",
        "\n",
        "```\n",
        "Tasks:\n",
        "  1. Data Preprocessing (5 points)\n",
        "  2. Conditional Generative adversarial network definition (5 points)\n",
        "  3. Conditional Generative adversarial network training (10 points)\n",
        "  4. Text explainer implemetation using Lime or Shap (5 bonus points)\n",
        "```\n",
        "\n",
        "<hr>"
      ],
      "id": "average-extension"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "composite-convenience"
      },
      "source": [
        "## The Dataset\n",
        "\n",
        "For this task the 20 newsgroups text dataset is used. [LINK](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html)"
      ],
      "id": "composite-convenience"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "average-creek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e638f136-b3cd-4834-b89b-7ced10fea3ef"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import numpy as np\n",
        "\n",
        "import nltk, string, re\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import Vocab\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Available device : {device}\")"
      ],
      "id": "average-creek",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Available device : cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rubber-november"
      },
      "source": [
        "## Task 1: Preprocessing of Dataset (5 points)\n",
        "\n",
        "\n",
        "\n",
        "1.  Loading and cleaning of Text data:\n",
        "    * Choose 4 categories from the dataset  \n",
        "    * Implement a method `clean_text` which will take text then make text lowercase, remove punctuation, whitespaces and stopwords\n",
        "    * Plot the distribution of classes/categories"
      ],
      "id": "rubber-november"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "secret-publisher"
      },
      "source": [
        "categories = ['rec.autos', 'rec.motorcycles', 'rec.sport.baseball','rec.sport.hockey'] #TODO: Choose 4 categories from the dataset\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups_valid = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))"
      ],
      "id": "secret-publisher",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "forward-invitation"
      },
      "source": [
        "def clean_text(text):\n",
        "    \"\"\" Function to perform common NLP pre-processing tasks. \"\"\"\n",
        "    # make lowercase\n",
        "\n",
        "    text = text.lower()\n",
        "\n",
        "\n",
        "    # remove punctuation\n",
        "\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    words=[word.lower() for word in words if word.isalpha()]\n",
        "\n",
        "    # remove numbers\n",
        "\n",
        "    # remove whitespaces\n",
        "\n",
        "    # remove stopwords\n",
        "    stop_words = set(stopwords.words('english')) \n",
        "  \n",
        "    filtered_sentence = [w for w in words if not w in stop_words] \n",
        "\n",
        "    # remove short words\n",
        "\n",
        "    filtered_sentence_4 = [w for w in words if len(w)>=4]\n",
        "\n",
        "    textt = \"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in filtered_sentence_4]).strip()\n",
        "\n",
        "    return textt"
      ],
      "id": "forward-invitation",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMJzRIZDA9lw"
      },
      "source": [
        "# print(clean_text(\"   Hello I a'm nbasdf BN asdf 1 2 2 2 asdfjkasd \"))"
      ],
      "id": "NMJzRIZDA9lw",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "generic-cathedral"
      },
      "source": [
        "train_sentences = []\n",
        "validation_sentences = []\n",
        "\n",
        "train_labels = []\n",
        "validation_labels = []\n",
        "\n",
        "\n",
        "# Clean training sentences\n",
        "for id in range(len(newsgroups_train.data)):\n",
        "    text = clean_text(newsgroups_train.data[id])\n",
        "    label = newsgroups_train.target[id]\n",
        "    if text:\n",
        "        train_sentences.append(text)\n",
        "        train_labels.append(label)\n",
        "\n",
        "# Clean validation sentences\n",
        "for id in range(len(newsgroups_valid.data)):\n",
        "    text = clean_text(newsgroups_valid.data[id])\n",
        "    label = newsgroups_valid.target[id]\n",
        "    if text:\n",
        "        validation_sentences.append(text)\n",
        "        validation_labels.append(label)"
      ],
      "id": "generic-cathedral",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nK4iXqzFzI0"
      },
      "source": [
        "categorie_s = ['autos', 'motorcycles', 'baseball','hockey']\n",
        "trainlabels = [categorie_s[i] for i in train_labels]\n",
        "\n",
        "validationlabels  = [categorie_s[i] for i in validation_labels]"
      ],
      "id": "6nK4iXqzFzI0",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Ked65TZ9D_8M",
        "outputId": "a62e184e-612a-4961-e3fb-bb7e7bab2b54"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "plt.hist(trainlabels)  # density=False would make counts\n",
        "plt.hist(validationlabels)  # density=False would make counts\n",
        "plt.legend([\"Train\", \"Validation\"])\n",
        "plt.ylabel('Distribution')\n",
        "plt.xlabel('Catagories');\n"
      ],
      "id": "Ked65TZ9D_8M",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEGCAYAAABCa2PoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAe1UlEQVR4nO3de5xd873/8ddbEhmERC5H/ZJolLQudUmMSwQVtO6CSo6USvD7pVQ1qFNpT0l+Ti+cqqqeVpuiCUUEVSlK3W9xmxBDBEmJmoiIIESkhM/5Y31n7CSTzE6y1szszPv5eOzHXuu7vmutz1778tnfdfkuRQRmZmZra72WDsDMzNYNTihmZpYLJxQzM8uFE4qZmeXCCcXMzHLRvqUDWBvdu3ePPn36tHQYZmYVZerUqW9FRI+8l1vRCaVPnz7U1NS0dBhmZhVF0qtFLLfQXV6Suki6UdILkmZIGiCpq6S7JM1Mz5umupJ0qaRZkmol9S8yNjMzy1fRx1B+BdwREdsAOwEzgNHAPRHRF7gnjQMcDPRNj5HAZQXHZmZmOSosoUjqDOwDXAEQER9FxLvAYGBCqjYBODINDwauisxjQBdJmxcVn5mZ5avIYyhbAvOBP0raCZgKjAI2i4i5qc4bwGZpuCfwWsn8dalsbkkZkkaStWDYYostCgvezJrXxx9/TF1dHUuWLGnpUNYZVVVV9OrViw4dOjTL+opMKO2B/sDpEfG4pF/x2e4tACIiJK1WZ2IRMQ4YB1BdXe2OyMzWEXV1dWy88cb06dMHSS0dTsWLCBYsWEBdXR1bbrlls6yzyGModUBdRDyexm8kSzDz6ndlpec30/Q5QO+S+XulMjNrA5YsWUK3bt2cTHIiiW7dujVri6+whBIRbwCvSfpSKtofeB6YDAxPZcOBW9LwZOCEdLbXHsDCkl1jZtYGOJnkq7m3Z9HXoZwOXCNpfeBl4ESyJDZJ0snAq8DQVPd24BBgFrA41TUzswpRaEKJiGlAdSOT9m+kbgCnFRmPmVWOPqNvy3V5sy84dJXTFyxYwP77Zz9Nb7zxBu3ataNHj+xi8ieeeIL1119/pfPW1NRw1VVXcemll+YXcAWq6CvlrXLk/eNQrqZ+RMzqdevWjWnTpgEwduxYOnXqxNlnn90wfenSpbRv3/hPZnV1NdXVjf13blucUMzMVmLEiBFUVVXx9NNPM3DgQI499lhGjRrFkiVL2GCDDRj9s1/RZ6u+PPnow0z4/a/5n/HXc9nFFzB3Th1z/jmbua/XcdzJp3LcSd/KPbYde3XJfZlrywnFzGwV6urqmDJlCu3ateO9997joYceon379tx9991ccOF/cfG4q1aYZ/Y/XuLy6//KBx8sYvBXdmXoN09qtmtBWpITipnZKgwZMoR27doBsHDhQoYPH87MmTORxKIP/9XoPHvv9zXW79iR9Tt2pGv3Hrz91ptstnnP5gy7RTihmK1jfLwqXxtttFHD8LnnnsugQYO4+eabmT17NgP33qfRedZfv2PD8HrrrcfSpZ8UHmdr4BtsmZmVaeHChfTsmbU0xo8f37LBtEJuoZhZq9QaWzzf//73GT58OD/+8Y859NDWF19Lc0IxM1vO2LFjGy0fMGAAL730UsP40FOy04p3HbAXuw7YC4BTz1qmy0L+fM+jxQTZCrXZhNJS+5mhdf7zMjNbWz6GYmZmuXBCMTOzXDihmJlZLpxQzMwsF04oZmaWizZ7lpeZtXJjO+e8vIWrnDxo0CBGjx7NgQce2FB2ySWX8OKLL3LZZZetUH/fffflW/8xhu136sdpJwzhZ7++nE06LxvzZRdfwIYbbsTwU05f6XrvveM2Pv+Frdjqi9sA8JuLfsouu+/JHnvvuxovrnVwC8XMDBg2bBgTJ05cpmzixIkMGzasyXl/c9UNKySTct135228PPPFhvHTzv5hRSYTcEIxMwPgmGOO4bbbbuOjjz4CYPbs2bz++utcd911VFdXs/322zNmzJhG5z14wI688/YCAP5w6UUcvk81w48+iNn/mNlQ56ZrJ/CNQ/djyNf24qyRJ/Dhh4uZVvM499/1Ny7+yXkMPXBvXpv9Cuee+W3uui27M/rjDz/A0IP24esH7Ml53/sOH/3rXw3rGzNmDP3792eHHXbghRdeKHLTlM0JxcwM6Nq1K7vttht/+9vfgKx1MnToUH7yk59QU1NDbW0tDzzwALW1tStdxvO107hj8p+ZdOeD/GbCJKY/83TDtP0PPpxrb7uXG/7+MF/Y+ovcPPFP7Fy9O/t+9WDO+s/zmXTnQ/Tus2VD/X8tWcK5Z32b//7tldx09xQ++WQpk66+smF69+7deeqppzj11FO56KKLCtgiq88JxcwsKd3tVb+7a9KkSfTv359+/foxffp0nn/++ZXO/9QTj7LfQYexwQYb0mnjTfjKVw9umDbrhRmMOPpgvn7Antz2lxv4x0szVhnL7Jdn0rP35+nzha0BOOKYYUx9fErD9KOPPhqAXXbZhdmzZ6/pS86VD8qbmSWDBw/mzDPP5KmnnmLx4sV07dqViy66iCeffJJNN92UESNGsGTJkjVa9rnf+zaXXP4nvrTdDtwy6VpqHn14rWLt2DHrIr9du3YsXbp0rZaVF7dQzMySTp06MWjQIE466SSGDRvGe++9x0YbbUTnzp2ZN29ew+6wldll9z25787bWPLhh3yw6H0evPuOhmmLFy2i+799jo8//pjb/3JDQ/mGnTrxwaJFKyyrzxf68nrdP/nnKy8DcOtN11O9x8CcXmkx3EIxs9apidN8izJs2DCOOuooJk6cyDbbbEO/fv3YZptt6N27NwMHrvoHfdsdduLAw49iyIF707V7d7bfqV/DtNPO/iHHH3EAm3btzg79dmFxSiIHHXE0559zBtf+8ff84ncTGup3rKri/F/8hrNPHcEnS5ey/U79GXL8icW86JwoIlo6hjVWXV0dNTU1azSvextuXr6LYPOp1G09Y8YMtt1225yiaR61de+22Lp37NWlrHqNbVdJUyOiOu+YvMvLzMxy4YRiZma5cEIxs1ajknfBt0bNvT0LTSiSZkt6VtI0STWprKukuyTNTM+bpnJJulTSLEm1kvoXGZuZtS5VVVUsWLDASSUnEcGCBQuoqqpqtnU2x1legyLirZLx0cA9EXGBpNFp/BzgYKBveuwOXJaezawN6NWrF3V1dcyfP7+lQynbvHc+bLF1z3h/gybrVFVV0atXr2aIJtMSpw0PBvZNwxOA+8kSymDgqsj+njwmqYukzSNibgvEaGbNrEOHDmy55ZZNV2xFDvbZosso+hhKAH+XNFXSyFS2WUmSeAPYLA33BF4rmbculZmZWQUouoWyV0TMkfRvwF2SlukSMyJC0mrtME2JaSTAFltskV+kZma2VgptoUTEnPT8JnAzsBswT9LmAOn5zVR9DtC7ZPZeqWz5ZY6LiOqIqO7Ro0eR4ZuZ2WooLKFI2kjSxvXDwNeA54DJwPBUbThwSxqeDJyQzvbaA1jo4ydmZpWjyF1emwE3S6pfz7URcYekJ4FJkk4GXgWGpvq3A4cAs4DFQOvutMbMzJZRWEKJiJeBnRopXwDs30h5AKcVFY+ZmRXLV8qbmVkunFDMzCwXTihmZpYLJxQzM8uFE4qZmeXCCcXMzHLhhGJmZrlwQjEzs1w4oZiZWS6cUMzMLBdOKGZmlgsnFDMzy4UTipmZ5cIJxczMcuGEYmZmuXBCMTOzXDihmJlZLpxQzMwsF04oZmaWCycUMzPLhROKmZnlwgnFzMxy4YRiZma5cEIxM7NcOKGYmVkunFDMzCwXTihmZpaLwhOKpHaSnpZ0axrfUtLjkmZJul7S+qm8Yxqflab3KTo2MzPLT3O0UEYBM0rGLwR+GRFbA+8AJ6fyk4F3UvkvUz0zM6sQhSYUSb2AQ4HL07iA/YAbU5UJwJFpeHAaJ03fP9U3M7MKUHQL5RLg+8Cnabwb8G5ELE3jdUDPNNwTeA0gTV+Y6i9D0khJNZJq5s+fX2TsZma2GgpLKJIOA96MiKl5LjcixkVEdURU9+jRI89Fm5nZWmhf4LIHAkdIOgSoAjYBfgV0kdQ+tUJ6AXNS/TlAb6BOUnugM7CgwPjMzCxHhbVQIuIHEdErIvoAxwL3RsRxwH3AManacOCWNDw5jZOm3xsRUVR8ZmaWryJbKCtzDjBR0o+Bp4ErUvkVwNWSZgFvkyUhW0fMrvpGC615YQut16ztaZaEEhH3A/en4ZeB3RqpswQY0hzxmJlZ/lqihWJmtk5ouZY3tMbWd1kJRVIP4P8BfUrniYiTignLzNaUdy9aSym3hXIL8BBwN/BJceGYmVmlKjehbBgR5xQaiZmZVbRyE8qtkg6JiNsLjaYZed+nmVm+yr0OZRRZUlki6f30eK/IwMzMrLKU1UKJiI2LDsTMzCpb2acNSzoC2CeN3h8RtxYTkpmZVaKydnlJuoBst9fz6TFK0s+KDMzMzCpLuS2UQ4CdI+JTAEkTyLpN+UFRgZmZWWVZnc4hu5QMd847EDMzq2zltlB+Bjwt6T5AZMdSRhcWlZmZVZxyz/K6TtL9wK6p6JyIeKOwqMzMrOKscpeXpG3Sc39gc7Jb9tYB/yeVmZmZAU23UM4CRgK/aGRaAPvlHpGZmVWkVSaUiBiZBg9O9ytpIKmqsKjMzKzilHuW15Qyy8zMrI1aZQtF0ueAnsAGkvqRneEFsAmwYcGxmZlZBWnqGMqBwAigF3BxSfn7wA8LisnMzCpQU8dQJgATJH09Im5qppjMzKwClXth45clbb98YUScn3M8ZmZWocpNKItKhquAw4AZ+YdjZmaVqtwr5Ze5DkXSRcCdhURkZmYVaXU6hyy1IdmBejMzM6DMFoqkZ8mujAdoB/QAfPzEzMwalHsM5bCS4aXAvIhYWkA8ZmZWocra5RURrwLdgMHA0cAOTc0jqUrSE5KekTRd0v9P5VtKelzSLEnXS1o/lXdM47PS9D5r+qLMzKz5lXsL4POACWRJpTswXtKPmpjtX8B+EbETsDNwkKQ9gAuBX0bE1sA7wMmp/snAO6n8l6memZlViHIPyh8H7BoRYyJiDLAH8M1VzRCZ+tONO6RHfQ/FN6byCcCRaXhwGidN319SfVcvZmbWypWbUF4nu/6kXkdgTlMzSWonaRrwJnAX8A/g3ZLjL3VkfYWRnl8DSNMXkrWIll/mSEk1kmrmz59fZvhmZla0pjqH/DVZq2IhMF3SXWn8q8ATTS08Ij4BdpbUBbgZ2GZtA46IccA4gOrq6miiupmZNZOmzvKqSc9TyRJCvftXZyUR8W66H/0AoIuk9qkV0ovPWjpzgN5AnaT2QGdgweqsx8zMWk45nUOuEUk9gI9TMtmArFVzIXAfcAwwERgO3JJmmZzGH03T740It0DMzCpEU7u8JkXE0OUubGwQETuuYvbNyXoqbkd2rGZSRNwq6XlgoqQfA08DV6T6VwBXS5oFvA0cu/ovx8zMWkpTu7xGpefDVlmrERFRC/RrpPxlYLdGypcAQ1Z3PWZm1jo0tctrbmphjI+IQc0Uk5mZVaAmTxtOZ2p9KqlzM8RjZmYVanXuh/JsOm34g/rCiPhuIVGZmVnFKTeh/Dk9SvkMLDMza1BuQukSEb8qLZA0amWVzcys7Sm365XhjZSNyDEOMzOrcE1dhzIM+AawpaTJJZM2IbtWxMzMDGh6l9cUYC5Zl/Wl95V/H6gtKigzM6s8TV2H8irwqqQDgA8j4lNJXyTr5PHZ5gjQzMwqQ7nHUB4EqiT1BP5Odi+U8UUFZWZmlafchKKIWEx2+9/fRsQQYPviwjIzs0pTdkKRNIDszo23pbJ2xYRkZmaVqNyEcgbwA+DmiJgu6Qtk3dCbmZkBZV7YGBEPAA+UjL8MuNsVMzNr0NR1KJdExBmS/krj90M5orDIzMysojTVQrk6PV9UdCBmZlbZmroOZWp6fiDd0peImN8cgZmZWWVp8qC8pLGS3gJeBF6SNF/SecWHZmZmlWSVCUXSWcBAYNeI6BoRmwK7AwMlndkcAZqZWWVoqoXyTWBYRLxSX5DO8DoeOKHIwMzMrLI0lVA6RMRbyxem4ygdignJzMwqUVMJ5aM1nGZmZm1MU6cN7yTpvUbKBVQVEI+ZmVWopk4bdn9dZmZWlnL78jIzM1slJxQzM8uFE4qZmeWisIQiqbek+yQ9L2m6pFGpvKukuyTNTM+bpnJJulTSLEm1kvoXFZuZmeWvyBbKUuB7EbEdsAdwmqTtgNHAPRHRF7gnjQMcDPRNj5HAZQXGZmZmOSssoUTE3Ih4Kg2/D8wAegKDgQmp2gTgyDQ8GLgqMo8BXSRtXlR8ZmaWr2Y5hiKpD9APeBzYLCLmpklvAJul4Z7AayWz1aWy5Zc1UlKNpJr5893xsZlZa1F4QpHUCbgJOCMilrlIMiKCRm7ctSoRMS4iqiOiukePHjlGamZma6PQhCKpA1kyuSYi/pyK59XvykrPb6byOUDvktl7pTIzM6sARZ7lJeAKYEZEXFwyaTIwPA0PB24pKT8hne21B7CwZNeYmZm1ck315bU2BpJ1f/+spGmp7IfABcAkSScDrwJD07TbgUOAWcBi4MQCYzMzs5wVllAi4mGyTiQbs38j9QM4rah4zMysWL5S3szMcuGEYmZmuXBCMTOzXDihmJlZLpxQzMwsF04oZmaWCycUMzPLhROKmZnlwgnFzMxy4YRiZma5cEIxM7NcOKGYmVkunFDMzCwXTihmZpYLJxQzM8uFE4qZmeXCCcXMzHLhhGJmZrlwQjEzs1w4oZiZWS6cUMzMLBdOKGZmlgsnFDMzy4UTipmZ5cIJxczMcuGEYmZmuSgsoUi6UtKbkp4rKesq6S5JM9Pzpqlcki6VNEtSraT+RcVlZmbFKLKFMh44aLmy0cA9EdEXuCeNAxwM9E2PkcBlBcZlZmYFKCyhRMSDwNvLFQ8GJqThCcCRJeVXReYxoIukzYuKzczM8tfcx1A2i4i5afgNYLM03BN4raReXSpbgaSRkmok1cyfP7+4SM3MbLW02EH5iAgg1mC+cRFRHRHVPXr0KCAyMzNbE82dUObV78pKz2+m8jlA75J6vVKZmZlViOZOKJOB4Wl4OHBLSfkJ6WyvPYCFJbvGzMysArQvasGSrgP2BbpLqgPGABcAkySdDLwKDE3VbwcOAWYBi4ETi4rLzMyKUVhCiYhhK5m0fyN1AzitqFjMzKx4vlLezMxy4YRiZma5cEIxM7NcOKGYmVkunFDMzCwXTihmZpYLJxQzM8uFE4qZmeXCCcXMzHLhhGJmZrlwQjEzs1w4oZiZWS6cUMzMLBdOKGZmlgsnFDMzy4UTipmZ5cIJxczMcuGEYmZmuXBCMTOzXDihmJlZLpxQzMwsF04oZmaWCycUMzPLhROKmZnlwgnFzMxy4YRiZma5cEIxM7NctKqEIukgSS9KmiVpdEvHY2Zm5Ws1CUVSO+A3wMHAdsAwSdu1bFRmZlauVpNQgN2AWRHxckR8BEwEBrdwTGZmViZFREvHAICkY4CDIuL/pvFvArtHxHeWqzcSGJlGvwS8uIar7A68tYbzWnH8vrQ+fk9ap7V5Xz4fET3yDAagfd4LLFpEjAPGre1yJNVERHUOIVmO/L60Pn5PWqfW+L60pl1ec4DeJeO9UpmZmVWA1pRQngT6StpS0vrAscDkFo7JzMzK1Gp2eUXEUknfAe4E2gFXRsT0Ale51rvNrBB+X1ofvyetU6t7X1rNQXkzM6tsrWmXl5mZVTAnFDMzy0WbTCiSjvRV+PmT1EfSc2u5jH0l3ZpXTG1RHu/DKpY9QtL/rOY8syV1T8OLioirUqXP+54ttO77JeV62nGbTCjAkWTdu5iZtaR9gdVKKJJazclUy1tnEoqkv0iaKml6upp+mX9Dko6RND79GzgC+LmkaZK2krSzpMck1Uq6WdKmaZ7vSno+lU9smVdWcdpJ+kN6H/4uaYNVbN+tJd0t6RlJT0naqnRBknaV9HR6j3aR9EB6j++UtHkqf6qkft/S8TauvaRrJM2QdKOkDSWdJ+lJSc9JGidJ0PjnXNJGkq6U9ER6D0q7Qeqd/t3OlDSmvrCx72BbkFqEL6Tfl5fSdj9A0iNpG+0mqWvaPrXpu7CjpD7AKcCZ6bdo77Sse1O9eyRtkdYxXtLvJD0O/Hdj3x1JV0k6siSuayQNltRO0kXpfa+VdHojr+Frkh5Ny7pBUqdUfkHJZ+OiJjdGRKwTD6Bret4AeA7oBiwqmX4MMD4NjweOKZlWC3wlDZ8PXJKGXwc6puEuLf0aW/sD6AMsBXZO45OA41exfR8HjkrDVcCGZP/YbiX71zYV2ALoAEwBeqS6/052WjnAfSXr+ylwektvh5Z+pPchgIFp/Erg7PrvSCq7Gjg8Da/wOU/b8vj6MuAlYCNgBDA3fb/qv2vVqd4K38E0PhvonoYXFfGaW8H2XgrsQPYnfWra5iLrj/AvwK+BMan+fsC0NDwWOLtkWX8Fhqfhk4C/pOHx6XvRLo039t35Skn9zsArZJeGnArcCLRf7n26H6gm68LlQWCjVH4OcF56j1/ks7OBm/wNXGdaKMB3JT0DPEZ2xX3fcmaS1JlsQz2QiiYA+6ThWuAaSceTfWCsaa9ExLQ0PBXYika2r6SNgZ4RcTNARCyJiMWpzrZk59gfHhH/JOuz7cvAXZKmAT8i60kB4HLgRGW9Vf87cG2xL69ivBYRj6ThPwF7AYMkPS7pWbIfte3T9MY+518DRqftfT/Zj9YWadpdEbEgIj4E/pyWDWv4HVxHvBIRz0bEp8B04J7IfoWfJUs4e5ElcSLiXqCbpE0aWc4APvsMX81n2xbghoj4ZGXfnfQd6yupBzAMuCkilgIHAL9Pw0TE28utcw+yQwCPpPd7OPB5YCGwBLhC0tHAYprQavfFrQ5J+5JttAERsVjS/WRfgNKLbKrWYNGHkiWXw4H/lLRD/ZtiK/WvkuFPyP7drq65ZO9XP7J/zwKmR8SARureBIwB7gWmRsSCNVjfumj5C8wC+C1Za+I1SWP57DuxwuecbJt/PSKW6XxV0u6NLXsV38G2ovRz/2nJ+Kdkv7Mf57COD8qocxXZXoFjgRPLXK7I/iQMW2GCtBuwP9kenu+Q/RFZqXWlhdIZeCd9kLchy7gA8yRtK2k94KiS+u8DGwNExELgHUl7p2nfBB5I8/SOiPvImoCdgU7N8FrWNY1u34h4H6ir3+crqaOkDVOdd8l+5H6WfqheBHpIGpDqdpC0PWT/zsh6V7gM+GMzvaZKsEX99gK+ATycht9K+8ePAVjF5/xO4PSS4yz9Spb91XRMYAOyE1weYeXfQcs8BBwHDX+A34qI9yj5LUqmkCUDUv2Hll9QE9+d8cAZqd7zqewu4FtKB/MldV1ukY8BAyVtnaZvJOmL6XPSOSJuB84EdmrqRa4rCeUOsoOQM4ALyDYQwGiy/Y5TyP711psI/Ec62LgVWRPv55JqgZ3J9vO3A/6Udg88DVwaEe82y6tZ9zS2fSFLLt9N5VOAz9XPEBHzgMPIbrrWj+wH8MK0S2Uay54Zcw3ZP8G/F/w6KsmLwGnpO7EpWcL9A9mxjTvJ+s6DlX/O/4vs2FWtpOlpvN4TZC3DWrLdKjWs/DtombHALumzfgHZdwKyYyZH1R+UB04n24VbS/b9GLWS5TX63Unfmxks++fqcuCfZO/lM2R/MBpExHyyY2PXpeU9CmxDluhuTWUPA2c19SLd9YpVPElnk/2TOrelYzFrSaml8izQP+19aVbrxDEUa7sk3Ux24H+V+3bN1nWSDgCuAH7ZEskE3EIxM7OcrCvHUMzMrIU5oZiZWS6cUMzMLBdOKNbmSPqcpImS/qGs76nbJX1xJXW7SPp2M8V1iqQTmmNdZkXwQXlrU9KFelOACRHxu1S2E7BJRKxwEZmyDvxujYgvFxxXe/fCYJXOLRRrawYBH9cnE4CIeAZ4OvXu+pSkZ/VZ77oXAFulC89+LqnTSuoh6VxJL0p6WNJ16foYtPLelu+XdImkGmCUpLEl82wl6Y7UgnooXX2OpCHKeo19RtKDzbLFzMrk61CsrfkyWaeVy1tC1nvre8puBvWYpMlkvS18OSJ2hoZ7UTRWrxr4Oln3FB2Ap0rWcxVZL8gPSDqfrO+xM9K09SOiOi17bEk844BTImJm6j/rt2TX2pwHHBgRcyStST9pZoVxQjHLCPippH3IunHpCWy2GvUGArekvsWWSPorrLQ36xtKlnf9CivI+lDaE7ghdaUF0DE9PwKMlzSJrKdfs1bDCcXamumkjhGXcxzQA9glIj6WNJvGe8stt165GutBdj3g3fpWUamIOCW1WA4FpkraxT0sW2vhYyjW1twLdFTJHQUl7Uh2/4c3U5IYlMZhxd5gO6+k3iPA4ZKqUgvjMFh5b9arCjD1QvuKpCEpPqUTB5C0VUQ8HhHnAfPJ7jti1iq4hWJtSkSEpKOASySdQ3bsZDZZb7CXpl53a4AXUv0Fym7l+hzwN+BC4K+N1HsyHUupBeaRddBX35/ScOB3qeO+lynvPhXHAZdJ+hHZMZmJwDNkvTb3Jdv1dk8qM2sVfNqwWU4kdYqIRSlxPAiMjAjf497aDLdQzPIzTtJ2ZMdUJjiZWFvjFoqZmeXCB+XNzCwXTihmZpYLJxQzM8uFE4qZmeXCCcXMzHLxv6WYO0Z9pS0MAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "careful-anniversary"
      },
      "source": [
        "## Create vocabulary"
      ],
      "id": "careful-anniversary"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qualified-excellence"
      },
      "source": [
        "# Create tokenizer\n",
        "en_tokenizer = get_tokenizer('spacy', language='en')\n",
        "\n",
        "# Create vocabulary\n",
        "def build_vocab(sentences, tokenizer):\n",
        "    counter = Counter()\n",
        "    for sentence in sentences:\n",
        "        counter.update(tokenizer(sentence))\n",
        "    return Vocab(counter, specials=['<unk>', '<pad>'])\n",
        "\n",
        "vocabulary = build_vocab(train_sentences, en_tokenizer)"
      ],
      "id": "qualified-excellence",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unlike-filename"
      },
      "source": [
        "## Add padding "
      ],
      "id": "unlike-filename"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecological-hormone"
      },
      "source": [
        "max_len = 128\n",
        "\n",
        "# Add Padding \n",
        "def create_dataset(sentences, labels, en_tokenizer, vocab, max_len=128):\n",
        "    res = []\n",
        "    for sentence in sentences:\n",
        "        sentence_tokens = [vocab[token] for token in en_tokenizer(sentence)]\n",
        "        if len(sentence_tokens) <= max_len:\n",
        "            sentence_tokens = sentence_tokens + [vocab['<pad>']]*(max_len-len(sentence_tokens))\n",
        "        else:\n",
        "            sentence_tokens = sentence_tokens[:max_len]\n",
        "        sentence_tensor = torch.tensor(sentence_tokens,dtype=torch.long)\n",
        "        res.append(sentence_tensor)\n",
        "        \n",
        "    return TensorDataset(torch.stack(res),torch.from_numpy(np.array(labels)))\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "PAD_IDX = vocabulary['<pad>']\n",
        "\n",
        "train_dataset = create_dataset(train_sentences,train_labels, en_tokenizer, vocabulary)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "validation_dataset = create_dataset(validation_sentences, validation_labels, en_tokenizer, vocabulary)"
      ],
      "id": "ecological-hormone",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E8V4m-_Upnm",
        "outputId": "bd70904f-1244-4fa9-e497-6bc4b28a86e6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "6E8V4m-_Upnm",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lt4DaVwAUo9d",
        "outputId": "ad4410a2-4fef-41c0-fada-b44c246d093a"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import numpy as np\n",
        "\n",
        "import nltk, string, re\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import Vocab\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Available device : {device}\")\n",
        "\n",
        "pathtrain_loader = '/content/drive/MyDrive/ML Labs/final/train_loader.pt'\n",
        "pathtrain_dataset = '/content/drive/MyDrive/ML Labs/final/train_dataset.pt'\n",
        "pathvalidation_dataset = '/content/drive/MyDrive/ML Labs/final/validation_dataset.pt'\n",
        "pathvocabulary = '/content/drive/MyDrive/ML Labs/final/vocabulary.pt'\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "max_len = 128\n",
        "\n",
        "# torch.save(train_loader, pathtrain_loader)\n",
        "# torch.save(train_dataset, pathtrain_dataset)\n",
        "# torch.save(validation_dataset,pathvalidation_dataset)\n",
        "# torch.save(vocabulary, pathvocabulary)"
      ],
      "id": "lt4DaVwAUo9d",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Available device : cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_9esefzWldg"
      },
      "source": [
        "train_loader = torch.load(pathtrain_loader)\n",
        "train_dataset = torch.load(pathtrain_dataset)\n",
        "validation_dataset = torch.load(pathvalidation_dataset)\n",
        "vocabulary = torch.load(pathvocabulary)"
      ],
      "id": "i_9esefzWldg",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "attached-reservoir"
      },
      "source": [
        "## Task 2: Conditional Generative adversarial network definition (5 points)\n",
        "\n",
        "1.  Models Definition:\n",
        "    * Define the Generator & Discriminator network (Achitecture of your choice) "
      ],
      "id": "attached-reservoir"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otherwise-reference",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b59342b7-a54a-4c1f-f41c-5cb3ea785380"
      },
      "source": [
        "# TODO: Implement the Generator & Discriminator class\n",
        "class Generator(nn.Module):\n",
        "    # initializers\n",
        "    def __init__(self,output_dim, noise_dim=32):\n",
        "        super(Generator, self).__init__()\n",
        "        embedingy = 128\n",
        "        self.label_emb = nn.Embedding(4, embedingy)\n",
        "        self.output_dim = output_dim\n",
        "        \n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(embedingy+noise_dim, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(1024, output_dim)\n",
        "        )\n",
        "\n",
        "    # forward method. Condition is should be incorporated to the model input \n",
        "    def forward(self, x, labels):\n",
        "        z = x.view(x.size(0), 100)\n",
        "        c = self.label_emb(labels)\n",
        "        print(\"x dimension\", x.shape)\n",
        "        print(\"c dimension\", c.shape)\n",
        "        x = torch.cat([z, c])\n",
        "        out = self.model(x)\n",
        "        return out.view(x.size(0), self.output_dim)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    # initializers\n",
        "    def __init__(self,input_size):\n",
        "        super(Discriminator, self).__init__()\n",
        "        embedingy = 128\n",
        "        self.label_emb = nn.Embedding(4, embedingy)\n",
        "        self.input_size = input_size\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_size, 1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    # forward method. Note: Condition is should be incorporated to the model input\n",
        "    def forward(self, x, labels):\n",
        "        x = x.view(x.size(0), self.input_size)\n",
        "        c = self.label_emb(labels)\n",
        "        print(\"x dimension\", x.shape)\n",
        "        print(\"c dimension\", c.shape)\n",
        "        x = torch.cat([x, c])\n",
        "        out = self.model(x)\n",
        "        return out.squeeze()\n",
        "\n",
        "# define discriminator and generator\n",
        "# TODO: specify the input and output size\n",
        "\n",
        "D = Discriminator(input_size=max_len).to(device).float()\n",
        "G = Generator(output_dim=max_len).to(device).float()\n",
        "\n",
        "print(G)\n",
        "print()\n",
        "print(D)"
      ],
      "id": "otherwise-reference",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  (label_emb): Embedding(4, 128)\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=160, out_features=256, bias=True)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
            "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (4): Linear(in_features=512, out_features=1024, bias=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (6): Linear(in_features=1024, out_features=128, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "Discriminator(\n",
            "  (label_emb): Embedding(4, 128)\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=1024, bias=True)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Dropout(p=0.3, inplace=False)\n",
            "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Dropout(p=0.3, inplace=False)\n",
            "    (9): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (10): Dropout(p=0.3, inplace=False)\n",
            "    (11): Linear(in_features=128, out_features=1, bias=True)\n",
            "    (12): Sigmoid()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sudden-delta"
      },
      "source": [
        "## Task 3: Conditional Generative adversarial network training (10 points)\n",
        "\n",
        "* Implement the Conditional Generative adversarial network training procedure \n",
        "* Define the optimizers for Generator and Discriminator network\n",
        "* Define the loss functions\n",
        "* Add Tensorboard to log the Generator and Discriminator loss (for both Training and Validation). For discriminator the loss on fake samples and real samples should be logged separately \n",
        "\n",
        "**NOTE:** It is not important that the loss decreases during the training loop for this task. It is important that the training procedure is correctly implemented"
      ],
      "id": "sudden-delta"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liable-castle"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "writer = SummaryWriter()\n",
        "\n",
        "# params\n",
        "learning_rate = 0.0001\n",
        "n_epochs = 10\n",
        "\n",
        "# TODO: Create optimizers for the discriminator and generator\n",
        "# d_optimizer = None\n",
        "# g_optimizer = None\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "d_optimizer = torch.optim.Adam(D.parameters(), lr=1e-4)\n",
        "g_optimizer = torch.optim.Adam(G.parameters(), lr=1e-4)\n",
        "\n",
        "#fixed noise for validation \n",
        "fixed_noise = torch.normal(0,1, (len(validation_dataset),max_len), dtype=torch.float, device=device)"
      ],
      "id": "liable-castle",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mfvGjYrOo_a"
      },
      "source": [
        "def generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion):\n",
        "    g_optimizer.zero_grad()\n",
        "    z = Variable(torch.randn(max_len, 100)).cuda()\n",
        "    fake_labels = Variable(torch.LongTensor(np.random.randint(0, max_len, batch_size))).cuda()\n",
        "    fake_images = generator(z, fake_labels)\n",
        "    validity = discriminator(fake_images, fake_labels)\n",
        "    g_loss = criterion(validity, Variable(torch.ones(max_len)).cuda())\n",
        "    g_loss.backward()\n",
        "    g_optimizer.step()\n",
        "    return g_loss.data[0]"
      ],
      "id": "7mfvGjYrOo_a",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUPQP-mPOqsO"
      },
      "source": [
        "def discriminator_train_step(batch_size, discriminator, generator, d_optimizer, criterion, real_images, labels):\n",
        "    d_optimizer.zero_grad()\n",
        "\n",
        "    # train with real images\n",
        "    real_validity = discriminator(real_images, labels)\n",
        "    print(real_validity.shape)\n",
        "    real_loss = criterion(real_validity, Variable(torch.ones(batch_size)).cuda())\n",
        "    \n",
        "    # train with fake images\n",
        "    # z = \n",
        "    z = Variable(torch.randn(max_len, 100)).cuda()\n",
        "    fake_labels = Variable(torch.LongTensor(np.random.randint(0, max_len, batch_size))).cuda()\n",
        "    fake_images = generator(z, fake_labels)\n",
        "    fake_validity = discriminator(fake_images, fake_labels)\n",
        "    fake_loss = criterion(fake_validity, Variable(torch.zeros(max_len)).cuda())\n",
        "    \n",
        "    d_loss = real_loss + fake_loss\n",
        "    d_loss.backward()\n",
        "    d_optimizer.step()\n",
        "    return d_loss.data[0]"
      ],
      "id": "gUPQP-mPOqsO",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gvp67ZIhZWz6"
      },
      "source": [
        "def real_loss(D_out):\n",
        "    batch_size = D_out.size(0)\n",
        "    labels = torch.ones(batch_size).to(device) # real labels = 1     \n",
        "    \n",
        "    # binary cross entropy with logits loss\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    # calculate loss\n",
        "    loss = criterion(D_out.squeeze(), labels)\n",
        "    return loss\n",
        "\n",
        "def fake_loss(D_out):\n",
        "    batch_size = D_out.size(0)\n",
        "    labels = torch.FloatTensor(batch_size).uniform_(0, 0.1).to(device) # fake labels approx 0\n",
        "    labels = labels.to(device)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    # calculate loss\n",
        "    loss = criterion(D_out.squeeze(), labels)\n",
        "    return loss"
      ],
      "id": "Gvp67ZIhZWz6",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "promotional-extra",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "58adb347-62ce-4a69-ae7c-44988ec2c89a"
      },
      "source": [
        "## TODO: Implement the training procedure and log train & validation loss using tensorboard\n",
        "# batch_size = 128\n",
        "for epoch in range(n_epochs):\n",
        "    print(\"loss\")\n",
        "    for x,y in train_loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        #Train discriminator\n",
        "\n",
        "        #Train generator\n",
        "\n",
        "        #validation \n",
        "\n",
        "        #Log Train and validation loss for G and D (training loss for fake and real separate) : Use tensorboard\n",
        "        real_texts = Variable(x).cuda()\n",
        "        labels = Variable(y).cuda()\n",
        "        G.train()\n",
        "        batch_size = real_texts.size(0)\n",
        "        d_loss = discriminator_train_step(len(real_texts), D,\n",
        "                                          G, d_optimizer, criterion,\n",
        "                                          real_texts, labels)\n",
        "        \n",
        "\n",
        "        g_loss = generator_train_step(batch_size, D, G, g_optimizer, criterion)\n",
        "        print(\"loss\")\n",
        "\n",
        "    generator.eval()\n",
        "    print('g_loss: {}, d_loss: {}'.format(g_loss, d_loss))\n",
        "    z = Variable(torch.randn(9, 100)).cuda()\n",
        "    labels = Variable(torch.LongTensor(np.arange(9))).cuda()\n",
        "    sample_images = generator(z, labels).unsqueeze(1).data.cpu()\n",
        "    grid = make_grid(sample_images, nrow=3, normalize=True).permute(1,2,0).numpy()\n",
        "    plt.imshow(grid)\n",
        "    plt.show()\n"
      ],
      "id": "promotional-extra",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss\n",
            "x dimension torch.Size([128, 128])\n",
            "c dimension torch.Size([128, 128])\n",
            "torch.Size([256])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-2df331329941>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         d_loss = discriminator_train_step(len(real_texts), D,\n\u001b[1;32m     21\u001b[0m                                           \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                                           real_texts, labels)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-2a2227f5c65a>\u001b[0m in \u001b[0;36mdiscriminator_train_step\u001b[0;34m(batch_size, discriminator, generator, d_optimizer, criterion, real_images, labels)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mreal_validity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_validity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mreal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_validity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# train with fake images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2753\u001b[0m         raise ValueError(\n\u001b[1;32m   2754\u001b[0m             \u001b[0;34m\"Using a target size ({}) that is different to the input size ({}) is deprecated. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2755\u001b[0;31m             \u001b[0;34m\"Please ensure they have the same size.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2756\u001b[0m         )\n\u001b[1;32m   2757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([256])) is deprecated. Please ensure they have the same size."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "fFp1dio6Zt-H",
        "outputId": "254106e1-be0c-4a6b-ce42-2576328b7bdc"
      },
      "source": [
        "## TODO: Implement the training procedure and log train & validation loss using tensorboard\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for x,y in train_loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        #Train discriminator\n",
        "        d_optimizer.zero_grad()\n",
        "        D_real = D(x, y)\n",
        "        d_real_loss = real_loss(D_real)\n",
        "\n",
        "        x_fake = torch.FloatTensor(y.shape[0],32).uniform_(0, 1000).to(device)\n",
        "        x_fake = G(x_fake, y)\n",
        "        D_fake = D(x_fake, y)\n",
        "        d_fake_loss = fake_loss(D_fake)\n",
        "        \n",
        "        d_loss = d_real_loss + d_fake_loss\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "        \n",
        "        #Train generator\n",
        "        g_optimizer.zero_grad()\n",
        "        z = torch.FloatTensor(y.shape[0],32).uniform_(0, 1000).to(device)\n",
        "        fake_x = G(z, y)\n",
        "        fake_losses = real_loss(D(fake_x, y))\n",
        "        fake_losses.backward()\n",
        "        g_optimizer.step()\n",
        "        #validation \n",
        "        # for x_val, y_val in val_loader:\n",
        "            \n",
        "        # #Log Train and validation loss for G and D (training loss for fake and real separate) : Use tensorboard\n",
        "        # writer.add_scalar(\"Train/generator\", fake_losses, epoch)\n",
        "        # writer.add_scalar(\"Train/discriminator\", d_loss, epoch)"
      ],
      "id": "fFp1dio6Zt-H",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x dimension torch.Size([128, 128])\n",
            "c dimension torch.Size([128, 128])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-ee88126a7f7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mD_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0md_fake_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfake_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-399495df1b2a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, labels)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# forward method. Condition is should be incorporated to the model input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x dimension\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[128, 100]' is invalid for input of size 4096"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eastern-guest"
      },
      "source": [
        "## Launch Tensorboard"
      ],
      "id": "eastern-guest"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oriented-examination"
      },
      "source": [
        "%tensorboard --logdir ./runs"
      ],
      "id": "oriented-examination",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "developmental-sewing"
      },
      "source": [
        "## Task 4: (Optional): Text explainer implemetation using Lime or Shap (5 bonus points)\n",
        "\n",
        "Using the [20 newsgroups](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html) text dataset is used.\n",
        "Create a simple(i.e Decision tree, Random Forest) multi-class classifier and explain the classifiers predictions with the help of LIME or SHARP. \n",
        "\n",
        "**Note:** Use TF-IDF for feature extraction"
      ],
      "id": "developmental-sewing"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dressed-mayor"
      },
      "source": [
        "newsgroups_train = fetch_20newsgroups(subset='train')\n",
        "newsgroups_test = fetch_20newsgroups(subset='test')\n",
        "\n",
        "clf = None"
      ],
      "id": "dressed-mayor",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "detailed-providence"
      },
      "source": [
        "## <center>Solution should be pushed to github and link to github submitted to Moodle</center>"
      ],
      "id": "detailed-providence"
    }
  ]
}